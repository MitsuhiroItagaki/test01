#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ•ã‚£ãƒ«ã‚¿ç‡æ©Ÿèƒ½çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
databricks_sql_profiler_analysis.pyã«ãƒ•ã‚£ãƒ«ã‚¿ç‡è¨ˆç®—æ©Ÿèƒ½ã‚’çµ±åˆã—ã¾ã™
"""

import re

def integrate_filter_rate_functionality():
    """
    ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ•ã‚£ãƒ«ã‚¿ç‡è¨ˆç®—æ©Ÿèƒ½ã‚’çµ±åˆ
    """
    
    # ãƒ•ã‚£ãƒ«ã‚¿ç‡è¨ˆç®—é–¢æ•°ã®ã‚³ãƒ¼ãƒ‰
    filter_rate_functions = '''
def calculate_filter_rate(node: Dict[str, Any]) -> Dict[str, Any]:
    """
    ãƒãƒ¼ãƒ‰ã‹ã‚‰Size of files prunedã¨Size of files readãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æŠ½å‡ºã—ã¦ãƒ•ã‚£ãƒ«ã‚¿ç‡ã‚’è¨ˆç®—
    
    Args:
        node: ãƒãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿
        
    Returns:
        Dict: ãƒ•ã‚£ãƒ«ã‚¿ç‡è¨ˆç®—çµæœ
    """
    filter_rate = None
    files_pruned_bytes = 0
    files_read_bytes = 0
    
    # detailed_metricsã‹ã‚‰æ¤œç´¢
    detailed_metrics = node.get('detailed_metrics', {})
    for metric_key, metric_info in detailed_metrics.items():
        metric_label = metric_info.get('label', '')
        metric_value = metric_info.get('value', 0)
        
        if metric_label == "Size of files pruned" and metric_value > 0:
            files_pruned_bytes = metric_value
        elif metric_label == "Size of files read" and metric_value > 0:
            files_read_bytes = metric_value
    
    # raw_metricsã‹ã‚‰æ¤œç´¢ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    if files_pruned_bytes == 0 or files_read_bytes == 0:
        raw_metrics = node.get('metrics', [])
        for metric in raw_metrics:
            metric_label = metric.get('label', '')
            metric_value = metric.get('value', 0)
            
            if metric_label == "Size of files pruned" and metric_value > 0:
                files_pruned_bytes = metric_value
            elif metric_label == "Size of files read" and metric_value > 0:
                files_read_bytes = metric_value
    
    # ãƒ•ã‚£ãƒ«ã‚¿ç‡è¨ˆç®—ï¼ˆä¸¡æ–¹ã®å€¤ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰
    if files_read_bytes > 0 and files_pruned_bytes > 0:
        filter_rate = files_pruned_bytes / files_read_bytes
    
    return {
        "filter_rate": filter_rate,
        "files_pruned_bytes": files_pruned_bytes,
        "files_read_bytes": files_read_bytes,
        "has_filter_metrics": files_read_bytes > 0 and files_pruned_bytes > 0
    }

def format_filter_rate_display(filter_result: Dict[str, Any]) -> str:
    """
    ãƒ•ã‚£ãƒ«ã‚¿ç‡è¨ˆç®—çµæœã‚’è¡¨ç¤ºç”¨æ–‡å­—åˆ—ã«å¤‰æ›
    
    Args:
        filter_result: calculate_filter_rate()ã®çµæœ
        
    Returns:
        str: è¡¨ç¤ºç”¨æ–‡å­—åˆ—
    """
    if not filter_result["has_filter_metrics"]:
        return None
    
    filter_rate = filter_result["filter_rate"]
    files_read_gb = filter_result["files_read_bytes"] / (1024 * 1024 * 1024)
    files_pruned_gb = filter_result["files_pruned_bytes"] / (1024 * 1024 * 1024)
    
    return f"ğŸ“‚ ãƒ•ã‚£ãƒ«ã‚¿ç‡: {filter_rate:.1%} (èª­ã¿è¾¼ã¿: {files_read_gb:.2f}GB, ãƒ—ãƒ«ãƒ¼ãƒ³: {files_pruned_gb:.2f}GB)"

'''

    # ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    with open('databricks_sql_profiler_analysis.py', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # 1. ãƒ•ã‚£ãƒ«ã‚¿ç‡è¨ˆç®—é–¢æ•°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«æœ«å°¾ã«è¿½åŠ 
    if 'def calculate_filter_rate(' not in content:
        content += '\n' + filter_rate_functions
        print("âœ… ãƒ•ã‚£ãƒ«ã‚¿ç‡è¨ˆç®—é–¢æ•°ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
    else:
        print("â„¹ï¸ ãƒ•ã‚£ãƒ«ã‚¿ç‡è¨ˆç®—é–¢æ•°ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    
    # 2. extract_detailed_bottleneck_analysisé–¢æ•°ã®node_analysisè¾æ›¸ã«ãƒ•ã‚£ãƒ«ã‚¿ç‡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ 
    # æ—¢å­˜ã®"severity"è¡Œã®å¾Œã«ãƒ•ã‚£ãƒ«ã‚¿ç‡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ 
    severity_pattern = r'"severity": "CRITICAL" if duration_ms >= 10000 else "HIGH" if duration_ms >= 5000 else "MEDIUM" if duration_ms >= 1000 else "LOW"'
    if severity_pattern in content and '"filter_rate"' not in content:
        new_severity_section = severity_pattern + ''',
            "filter_rate": None,
            "files_pruned_bytes": 0,
            "files_read_bytes": 0,
            "has_filter_metrics": False'''
        content = content.replace(severity_pattern, new_severity_section)
        print("âœ… node_analysisè¾æ›¸ã«ãƒ•ã‚£ãƒ«ã‚¿ç‡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
    
    # 3. ãƒ•ã‚£ãƒ«ã‚¿ç‡è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ ï¼ˆnode_analysisè¾æ›¸ä½œæˆå¾Œï¼‰
    node_analysis_creation_pattern = r'(        detailed_analysis\["top_bottleneck_nodes"\]\.append\(node_analysis\))'
    if not re.search(r'filter_result = calculate_filter_rate\(node\)', content):
        filter_calculation_code = '''
        # ãƒ•ã‚£ãƒ«ã‚¿ç‡è¨ˆç®—ã¨æƒ…å ±æ›´æ–°
        filter_result = calculate_filter_rate(node)
        node_analysis.update({
            "filter_rate": filter_result["filter_rate"],
            "files_pruned_bytes": filter_result["files_pruned_bytes"],
            "files_read_bytes": filter_result["files_read_bytes"],
            "has_filter_metrics": filter_result["has_filter_metrics"]
        })
        
        \\1'''
        content = re.sub(node_analysis_creation_pattern, filter_calculation_code, content)
        print("âœ… extract_detailed_bottleneck_analysisé–¢æ•°ã«ãƒ•ã‚£ãƒ«ã‚¿ç‡è¨ˆç®—ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
    
    # 4. TOP10ãƒ¬ãƒãƒ¼ãƒˆé–¢æ•°ã«ãƒ•ã‚£ãƒ«ã‚¿ç‡è¡¨ç¤ºã‚’è¿½åŠ 
    efficiency_pattern = r'(            if duration_ms > 0:\n                rows_per_sec = \(rows_num \* 1000\) / duration_ms\n                report_lines\.append\(f"    ğŸš€ å‡¦ç†åŠ¹ç‡: {rows_per_sec:>8,.0f} è¡Œ/ç§’"\))'
    if not re.search(r'ãƒ•ã‚£ãƒ«ã‚¿ç‡è¡¨ç¤º', content):
        filter_display_code = '''\\1
            
            # ãƒ•ã‚£ãƒ«ã‚¿ç‡è¡¨ç¤º
            filter_result = calculate_filter_rate(node)
            filter_display = format_filter_rate_display(filter_result)
            if filter_display:
                report_lines.append(f"    {filter_display}")'''
        content = re.sub(efficiency_pattern, filter_display_code, content)
        print("âœ… TOP10ãƒ¬ãƒãƒ¼ãƒˆé–¢æ•°ã«ãƒ•ã‚£ãƒ«ã‚¿ç‡è¡¨ç¤ºã‚’è¿½åŠ ã—ã¾ã—ãŸ")
    
    # å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã¿
    with open('databricks_sql_profiler_analysis.py', 'w', encoding='utf-8') as f:
        f.write(content)
    
    print("ğŸ‰ ãƒ•ã‚£ãƒ«ã‚¿ç‡æ©Ÿèƒ½ã®çµ±åˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    # çµ±åˆå¾Œã®èª¬æ˜
    print("\n=== çµ±åˆã•ã‚ŒãŸæ©Ÿèƒ½ ===")
    print("1. âœ… calculate_filter_rate() - ãƒ•ã‚£ãƒ«ã‚¿ç‡è¨ˆç®—é–¢æ•°")
    print("2. âœ… format_filter_rate_display() - ãƒ•ã‚£ãƒ«ã‚¿ç‡è¡¨ç¤ºãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé–¢æ•°") 
    print("3. âœ… extract_detailed_bottleneck_analysis() - ã‚»ãƒ«33è©³ç´°åˆ†æã«ãƒ•ã‚£ãƒ«ã‚¿ç‡è¿½åŠ ")
    print("4. âœ… generate_top10_time_consuming_processes_report() - TOP10ãƒ¬ãƒãƒ¼ãƒˆã«ãƒ•ã‚£ãƒ«ã‚¿ç‡è¡¨ç¤ºè¿½åŠ ")
    print("5. âœ… ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ› - node_analysisã«å«ã¾ã‚Œã‚‹ãƒ•ã‚£ãƒ«ã‚¿ç‡æƒ…å ±ãŒè‡ªå‹•çš„ã«ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›ã«å«ã¾ã‚Œã‚‹")
    
    print("\n=== è¡¨ç¤ºã•ã‚Œã‚‹æƒ…å ± ===")
    print("- ğŸ“‚ ãƒ•ã‚£ãƒ«ã‚¿ç‡: XX.X% (èª­ã¿è¾¼ã¿: X.XXG, ãƒ—ãƒ«ãƒ¼ãƒ³: X.XXGB)")
    print("- Size of files prunedã¨Size of files readã®ä¸¡æ–¹ãŒæ¤œå‡ºã•ã‚ŒãŸãƒãƒ¼ãƒ‰ã®ã¿è¡¨ç¤º")

if __name__ == "__main__":
    integrate_filter_rate_functionality() 