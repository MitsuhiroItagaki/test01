#!/usr/bin/env python3
"""
æ”¹å–„ã•ã‚ŒãŸã‚¹ãƒ”ãƒ«æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ã‚»ãƒ«12ã®å¼·åŒ–ã•ã‚ŒãŸã‚¹ãƒ”ãƒ«æ¤œå‡ºæ©Ÿèƒ½ã‚’æ¤œè¨¼
"""

import json

def test_improved_spill_detection(profiler_data):
    """æ”¹å–„ã•ã‚ŒãŸã‚»ãƒ«12ã‚¹ã‚¿ã‚¤ãƒ«ã®ã‚¹ãƒ”ãƒ«æ¤œå‡ºã‚’ãƒ†ã‚¹ãƒˆ"""
    print(f"ğŸ”¬ æ”¹å–„ã•ã‚ŒãŸã‚»ãƒ«12ã‚¹ãƒ”ãƒ«æ¤œå‡ºãƒ†ã‚¹ãƒˆ:")
    
    if 'graphs' not in profiler_data or not profiler_data['graphs']:
        print("  ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    graph = profiler_data['graphs'][0]
    nodes = graph.get('nodes', [])
    print(f"  {len(nodes)}å€‹ã®ãƒãƒ¼ãƒ‰ã‚’æ¤œæŸ»ä¸­...")
    
    total_spill_detected = False
    total_spill_bytes = 0
    spill_details = []
    
    for i, node in enumerate(nodes):
        if node.get('hidden', False):
            continue
            
        node_name = node.get('name', '')
        node_id = node.get('id', '')
        
        # ãƒãƒ¼ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è©³ç´°åˆ†æ
        node_spill_detected = False
        node_spill_bytes = 0
        node_spill_details = []
        spill_metrics_found = 0
        
        print(f"\n    ğŸ“‹ ãƒãƒ¼ãƒ‰{i+1}: {node_name} (ID: {node_id})")
        
        # 1. node.metricsã‹ã‚‰ã®è©³ç´°æ¤œæŸ»
        for metric in node.get('metrics', []):
            metric_key = metric.get('key', '')
            metric_label = metric.get('label', '')
            metric_value = metric.get('value', 0)
            
            # æ”¹å–„ã•ã‚ŒãŸã‚¹ãƒ”ãƒ«æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯
            spill_patterns = ['SPILL', 'DISK', 'PRESSURE']
            
            is_spill_metric = False
            metric_key_clean = metric_key.upper().replace(' ', '').replace('-', '').replace('_', '')
            metric_label_clean = metric_label.upper().replace(' ', '').replace('-', '').replace('_', '')
            
            # åŸºæœ¬çš„ãªã‚¹ãƒ”ãƒ«é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œæŸ»
            for pattern in spill_patterns:
                if pattern in metric_key_clean or pattern in metric_label_clean:
                    is_spill_metric = True
                    break
            
            # ã‚ˆã‚Šå…·ä½“çš„ãªã‚¹ãƒ”ãƒ«é–¢é€£ã®çµ„ã¿åˆã‚ã›ãƒ‘ã‚¿ãƒ¼ãƒ³
            spill_combinations = [
                ('SPILL', 'DISK'),      # "spilled to disk"
                ('SPILL', 'MEMORY'),    # "spilled due to memory"
                ('BYTES', 'SPILL'),     # "bytes spilled"
                ('ROWS', 'SPILL'),      # "rows spilled"
                ('SINK', 'SPILL'),      # "Sink spill"
                ('SPILL', 'PRESSURE'),  # "spilled due to pressure"
            ]
            
            for word1, word2 in spill_combinations:
                if (word1 in metric_key_clean and word2 in metric_key_clean) or \
                   (word1 in metric_label_clean and word2 in metric_label_clean):
                    is_spill_metric = True
                    break
            
            if is_spill_metric:
                spill_metrics_found += 1
                status = "ğŸ”´ å€¤ã‚ã‚Š" if metric_value > 0 else "âšª å€¤ã‚¼ãƒ­"
                print(f"      {status} {metric_key}")
                if metric_label and metric_label != metric_key:
                    print(f"        ãƒ©ãƒ™ãƒ«: {metric_label}")
                
                if metric_value > 0:
                    print(f"        å€¤: {metric_value:,} bytes ({metric_value/1024/1024:.2f} MB)")
                    node_spill_detected = True
                    node_spill_bytes += metric_value
                    node_spill_details.append({
                        'metric_name': metric_key,
                        'value': metric_value,
                        'label': metric_label
                    })
                else:
                    print(f"        å€¤: {metric_value}")
        
        # 2. keyMetricsã‹ã‚‰ã®æ¤œæŸ»
        key_metrics = node.get('keyMetrics', {})
        for key_metric_name, key_metric_value in key_metrics.items():
            if ('spill' in key_metric_name.lower() or 'disk' in key_metric_name.lower()) and key_metric_value > 0:
                node_spill_detected = True
                node_spill_bytes += key_metric_value
                node_spill_details.append({
                    'metric_name': f"keyMetrics.{key_metric_name}",
                    'value': key_metric_value,
                    'label': f"Key metric: {key_metric_name}"
                })
                print(f"      ğŸ”´ keyMetrics.{key_metric_name} = {key_metric_value:,}")
        
        # ãƒãƒ¼ãƒ‰çµæœã®ã‚µãƒãƒªãƒ¼
        if node_spill_detected:
            total_spill_detected = True
            total_spill_bytes += node_spill_bytes
            spill_details.extend(node_spill_details)
            print(f"      âœ… ãƒãƒ¼ãƒ‰ã‚¹ãƒ”ãƒ«æ¤œå‡º: {node_spill_bytes:,} bytes")
        elif spill_metrics_found > 0:
            print(f"      âšª {spill_metrics_found}å€‹ã®ã‚¹ãƒ”ãƒ«é–¢é€£ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚ã‚Šï¼ˆã™ã¹ã¦å€¤ã‚¼ãƒ­ï¼‰")
        else:
            print(f"      âŒ ã‚¹ãƒ”ãƒ«é–¢é€£ãƒ¡ãƒˆãƒªã‚¯ã‚¹æœªæ¤œå‡º")
        
        # æœ€åˆã®5ãƒãƒ¼ãƒ‰ã®ã¿è©³ç´°è¡¨ç¤º
        if i >= 4:
            remaining_nodes = len(nodes) - i - 1
            if remaining_nodes > 0:
                print(f"    ... ä»– {remaining_nodes} ãƒãƒ¼ãƒ‰")
            break
    
    print(f"\n  ğŸ“Š ç·åˆçµæœ:")
    print(f"    ã‚¹ãƒ”ãƒ«æ¤œå‡º: {'ã‚ã‚Š' if total_spill_detected else 'ãªã—'}")
    print(f"    ç·ã‚¹ãƒ”ãƒ«é‡: {total_spill_bytes:,} bytes ({total_spill_bytes/1024/1024:.2f} MB)")
    print(f"    æ¤œå‡ºã•ã‚ŒãŸã‚¹ãƒ”ãƒ«ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ•°: {len(spill_details)}")
    
    return total_spill_detected

def create_largeplan_mock_data():
    """test01/largeplan.jsonç›¸å½“ã®ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    # å®Ÿéš›ã®ã‚¹ãƒ”ãƒ«ãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã‚·ãƒŠãƒªã‚ªã‚’æ¨¡æ“¬
    mock_data = {
        "query": {
            "metrics": {
                "spillToDiskBytes": 5000000000,  # 5GB - ã‚»ãƒ«11ã§æ¤œå‡ºã•ã‚Œã‚‹
                "totalTimeMs": 180000  # 3åˆ†
            }
        },
        "graphs": [{
            "nodes": [
                {
                    "id": "large_shuffle_1",
                    "name": "Large Shuffle Exchange Sink",
                    "hidden": False,
                    "keyMetrics": {
                        "rowsNum": 10000000,
                        "durationMs": 45000,
                        "peakMemoryBytes": 8589934592  # 8GB
                    },
                    "metrics": [
                        {
                            "key": "Sink - Num bytes spilled to disk due to memory pressure",
                            "label": "Number of bytes spilled to disk due to memory pressure",
                            "value": 2147483648,  # 2GB ã‚¹ãƒ”ãƒ«
                            "metricType": "SIZE_METRIC_BYTES"
                        },
                        {
                            "key": "Sink - Num rows spilled to disk due to memory pressure", 
                            "label": "Number of rows spilled to disk due to memory pressure",
                            "value": 500000,
                            "metricType": "UNKNOWN_TYPE"
                        },
                        {
                            "key": "Sink - Num spills to disk due to memory pressure",
                            "label": "Number of spills to disk due to memory pressure", 
                            "value": 5,
                            "metricType": "UNKNOWN_TYPE"
                        }
                    ]
                },
                {
                    "id": "large_aggregate_1",
                    "name": "Large Grouping Aggregate", 
                    "hidden": False,
                    "keyMetrics": {
                        "rowsNum": 5000000,
                        "durationMs": 60000,
                        "peakMemoryBytes": 4294967296  # 4GB
                    },
                    "metrics": [
                        {
                            "key": "Num bytes spilled to disk due to memory pressure",
                            "label": "Number of bytes spilled to disk due to memory pressure",
                            "value": 1073741824,  # 1GB ã‚¹ãƒ”ãƒ«
                            "metricType": "SIZE_METRIC_BYTES"
                        },
                        {
                            "key": "Num rows spilled to disk due to memory pressure",
                            "label": "Number of rows spilled to disk due to memory pressure", 
                            "value": 250000,
                            "metricType": "UNKNOWN_TYPE"
                        }
                    ]
                },
                {
                    "id": "normal_scan_1",
                    "name": "Scan large_table",
                    "hidden": False,
                    "keyMetrics": {
                        "rowsNum": 100000000,
                        "durationMs": 30000
                    },
                    "metrics": [
                        {
                            "key": "Size of data read with io requests",
                            "label": "Size of data read with io requests",
                            "value": 10737418240,  # 10GBèª­ã¿è¾¼ã¿ã€ã‚¹ãƒ”ãƒ«ãªã—
                            "metricType": "SIZE_METRIC_BYTES"
                        }
                    ]
                }
            ]
        }]
    }
    
    with open('largeplan_mock.json', 'w', encoding='utf-8') as f:
        json.dump(mock_data, f, indent=2, ensure_ascii=False)
    
    print("ğŸ“ largeplan.jsonç›¸å½“ã®ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã—ãŸ: largeplan_mock.json")
    return mock_data

if __name__ == "__main__":
    print("ğŸ§ª æ”¹å–„ã•ã‚ŒãŸã‚¹ãƒ”ãƒ«æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    # 1. æ—¢å­˜ã®simple0.jsonã‚’ãƒ†ã‚¹ãƒˆ
    print("1ï¸âƒ£ simple0.json ã§ã®æ”¹å–„ãƒ†ã‚¹ãƒˆ")
    try:
        with open('simple0.json', 'r', encoding='utf-8') as f:
            simple_data = json.load(f)
        test_improved_spill_detection(simple_data)
    except Exception as e:
        print(f"âŒ simple0.jsonèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    print("\n" + "=" * 80)
    
    # 2. ã‚¹ãƒ”ãƒ«ã‚ã‚Šã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
    print("2ï¸âƒ£ ã‚¹ãƒ”ãƒ«ä»˜ãã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ã®æ”¹å–„ãƒ†ã‚¹ãƒˆ")
    try:
        with open('sample_spill_data.json', 'r', encoding='utf-8') as f:
            sample_data = json.load(f)
        test_improved_spill_detection(sample_data)
    except Exception as e:
        print(f"âŒ sample_spill_data.jsonèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    print("\n" + "=" * 80)
    
    # 3. largeplan.jsonç›¸å½“ã®å¤§è¦æ¨¡ã‚¹ãƒ”ãƒ«ã‚·ãƒŠãƒªã‚ªã‚’ãƒ†ã‚¹ãƒˆ
    print("3ï¸âƒ£ largeplan.jsonç›¸å½“ã®å¤§è¦æ¨¡ã‚¹ãƒ”ãƒ«ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ")
    mock_data = create_largeplan_mock_data()
    test_improved_spill_detection(mock_data)