# Databricks SQLãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼åˆ†æãƒ„ãƒ¼ãƒ«

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![Databricks](https://img.shields.io/badge/Databricks-Compatible-orange.svg)](https://databricks.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> Databricksã®SQLãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã€AIã‚’æ´»ç”¨ã—ã¦ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç‰¹å®šã—ã€å…·ä½“çš„ãªæ”¹å–„æ¡ˆã‚’æç¤ºã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚

## ğŸ“‹ ç›®æ¬¡

- [æ¦‚è¦](#æ¦‚è¦)
- [ä¸»è¦æ©Ÿèƒ½](#ä¸»è¦æ©Ÿèƒ½)
- [è¦ä»¶](#è¦ä»¶)
- [ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—](#ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
- [è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³](#è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³)
- [å‡ºåŠ›ä¾‹](#å‡ºåŠ›ä¾‹)
- [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
- [ãƒ©ã‚¤ã‚»ãƒ³ã‚¹](#ãƒ©ã‚¤ã‚»ãƒ³ã‚¹)

## ğŸ¯ æ¦‚è¦

ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ã€Databricksã®SQLãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼ãŒå‡ºåŠ›ã™ã‚‹JSONãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã€ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ï¼š

- **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹æŠ½å‡º**: å®Ÿè¡Œæ™‚é–“ã€ãƒ‡ãƒ¼ã‚¿é‡ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ãªã©ã®è©³ç´°åˆ†æ
- **AIã«ã‚ˆã‚‹ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æ**: è¤‡æ•°ã®LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‚’ä½¿ç”¨ã—ãŸã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªåˆ†æ
- **Liquid Clusteringæ¨å¥¨**: ãƒ†ãƒ¼ãƒ–ãƒ«æœ€é©åŒ–ã®ãŸã‚ã®å…·ä½“çš„ãªå®Ÿè£…ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
- **BROADCASTåˆ†æ**: å®Ÿè¡Œãƒ—ãƒ©ãƒ³ã‹ã‚‰ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚µã‚¤ã‚ºæ¨å®šã¨JOINæœ€é©åŒ–
- **SQLã‚¯ã‚¨ãƒªæœ€é©åŒ–**: å…ƒã®ã‚¯ã‚¨ãƒªã®æ”¹å–„ç‰ˆã‚’è‡ªå‹•ç”Ÿæˆ

## âœ¨ ä¸»è¦æ©Ÿèƒ½

### ğŸ” åŒ…æ‹¬çš„ãªåˆ†ææ©Ÿèƒ½
- **å®Ÿè¡Œãƒ—ãƒ©ãƒ³åˆ†æ**: Sparkå®Ÿè¡Œãƒ—ãƒ©ãƒ³ã®è©³ç´°è§£æ
- **Photonã‚¨ãƒ³ã‚¸ãƒ³åˆ†æ**: Photonåˆ©ç”¨çŠ¶æ³ã¨æœ€é©åŒ–ææ¡ˆ
- **ä¸¦åˆ—åº¦ãƒ»ã‚·ãƒ£ãƒƒãƒ•ãƒ«åˆ†æ**: å‡¦ç†åŠ¹ç‡ã®è©³ç´°è©•ä¾¡
- **ãƒ¡ãƒ¢ãƒªã‚¹ãƒ”ãƒ«æ¤œå‡º**: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å•é¡Œç‰¹å®š

### ğŸ¤– AIé§†å‹•ã®åˆ†æ
- **ãƒãƒ«ãƒLLMã‚µãƒãƒ¼ãƒˆ**: Databricksã€OpenAIã€Azure OpenAIã€Anthropicå¯¾å¿œ
- **æ—¥æœ¬èªãƒ»è‹±èªå¯¾å¿œ**: åˆ†æçµæœã®å¤šè¨€èªå‡ºåŠ›
- **ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ**: å®Ÿè¡Œç’°å¢ƒã‚’è€ƒæ…®ã—ãŸæœ€é©åŒ–ææ¡ˆ

### ğŸ“Š é«˜åº¦ãªæœ€é©åŒ–æ©Ÿèƒ½
- **Liquid Clustering**: Databricks SQLæº–æ‹ ã®æ­£ã—ã„æ§‹æ–‡ã§ã®å®Ÿè£…
- **BROADCASTæœ€é©åŒ–**: æ—¢å­˜ã®æœ€é©åŒ–çŠ¶æ³ã‚’è€ƒæ…®ã—ãŸæ¨å¥¨
- **ã‚¯ã‚¨ãƒªæœ€é©åŒ–**: å…ƒã®SQLã‚¯ã‚¨ãƒªã®æ”¹å–„ç‰ˆç”Ÿæˆ

## ğŸ“‹ è¦ä»¶

### åŸºæœ¬è¦ä»¶
- Python 3.8ä»¥ä¸Š
- Databricks Runtime 10.4ä»¥ä¸Š
- Databricksã®SQLãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼JSONãƒ•ã‚¡ã‚¤ãƒ«

### ä¾å­˜é–¢ä¿‚
```python
import json
import pandas as pd
import requests
from typing import Dict, List, Any
from datetime import datetime
```

### LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆã„ãšã‚Œã‹ä¸€ã¤ï¼‰
- **Databricks Model Serving**: æ¨å¥¨ï¼ˆé«˜é€Ÿï¼‰
- **OpenAI API**: GPT-4oã€GPT-4-turboå¯¾å¿œ
- **Azure OpenAI**: ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºåˆ©ç”¨
- **Anthropic API**: Claude-3.5-sonnetå¯¾å¿œ

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
Databricksã®FileStoreã¾ãŸã¯Volumesã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼š

```python
# FileStoreã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰
dbutils.fs.cp("file:/local/path/profiler.json", "dbfs:/FileStore/profiler.json")

# Unity Catalog Volumesã‚’ä½¿ç”¨
dbutils.fs.cp("file:/local/path/profiler.json", "/Volumes/catalog/schema/volume/profiler.json")
```

### 2. LLMã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®è¨­å®š

#### Databricks Model Servingï¼ˆæ¨å¥¨ï¼‰
```python
LLM_CONFIG = {
    "provider": "databricks",
    "databricks": {
        "endpoint_name": "databricks-claude-3-7-sonnet",
        "max_tokens": 131072,
        "temperature": 0.0
    }
}
```

#### OpenAI API
```python
LLM_CONFIG = {
    "provider": "openai",
    "openai": {
        "api_key": "your-openai-api-key",
        "model": "gpt-4o",
        "max_tokens": 16000,
        "temperature": 0.0
    }
}
```

### 3. åŸºæœ¬è¨­å®š
```python
# åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
JSON_FILE_PATH = '/FileStore/shared_uploads/your_username/profiler.json'

# å‡ºåŠ›è¨€èªè¨­å®š
OUTPUT_LANGUAGE = 'ja'  # 'ja' = æ—¥æœ¬èª, 'en' = è‹±èª
```

## ğŸ’» ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

1. **JSONãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿**
```python
profiler_data = load_profiler_json(JSON_FILE_PATH)
```

2. **ãƒ¡ãƒˆãƒªã‚¯ã‚¹æŠ½å‡º**
```python
metrics = extract_performance_metrics(profiler_data)
```

3. **AIã«ã‚ˆã‚‹åˆ†æ**
```python
analysis_result = analyze_bottlenecks_with_llm(metrics)
```

4. **æœ€é©åŒ–ã‚¯ã‚¨ãƒªç”Ÿæˆ**
```python
original_query = extract_original_query_from_profiler_data(profiler_data)
optimized_query = generate_optimized_query_with_llm(original_query, analysis_result, metrics)
```

### å®Œå…¨ãªåˆ†æãƒ•ãƒ­ãƒ¼

```python
# 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
profiler_data = load_profiler_json(JSON_FILE_PATH)
extracted_metrics = extract_performance_metrics(profiler_data)

# 2. ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æ
analysis_result = analyze_bottlenecks_with_llm(extracted_metrics)

# 3. Liquid Clusteringåˆ†æ
clustering_analysis = analyze_liquid_clustering_opportunities(profiler_data, extracted_metrics)

# 4. BROADCASTåˆ†æ
original_query = extract_original_query_from_profiler_data(profiler_data)
plan_info = extract_execution_plan_info(profiler_data)
broadcast_analysis = analyze_broadcast_feasibility(extracted_metrics, original_query, plan_info)

# 5. æœ€é©åŒ–ã‚¯ã‚¨ãƒªç”Ÿæˆ
optimized_query = generate_optimized_query_with_llm(original_query, analysis_result, extracted_metrics)

# 6. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
save_optimized_sql_files(original_query, optimized_query, extracted_metrics)
```

## âš™ï¸ è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³

### LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼è¨­å®š

| ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ | è¨­å®šã‚­ãƒ¼ | èª¬æ˜ |
|-------------|----------|------|
| Databricks | `endpoint_name` | Model Servingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå |
| OpenAI | `api_key`, `model` | APIã‚­ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ«å |
| Azure OpenAI | `api_key`, `endpoint`, `deployment_name` | Azureå›ºæœ‰ã®è¨­å®š |
| Anthropic | `api_key`, `model` | Anthropicã®APIã‚­ãƒ¼ã¨ãƒ¢ãƒ‡ãƒ« |

### åˆ†æã‚ªãƒ—ã‚·ãƒ§ãƒ³

| ã‚ªãƒ—ã‚·ãƒ§ãƒ³ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ | èª¬æ˜ |
|-----------|-----------|------|
| `OUTPUT_LANGUAGE` | 'ja' | å‡ºåŠ›è¨€èªï¼ˆ'ja'ã¾ãŸã¯'en'ï¼‰ |
| `max_tokens` | 131072 | LLMã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•° |
| `temperature` | 0.0 | LLMã®å‡ºåŠ›ãƒ©ãƒ³ãƒ€ãƒ æ€§ |

## ğŸ“Š å‡ºåŠ›ä¾‹

### ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æçµæœ
```
ğŸ”§ **Databricks SQLãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼ ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æçµæœ**

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¦‚è¦
- **å®Ÿè¡Œæ™‚é–“**: 45.2ç§’
- **èª­ã¿è¾¼ã¿ãƒ‡ãƒ¼ã‚¿é‡**: 2.1GB
- **ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡**: 85.3%
- **ãƒ‡ãƒ¼ã‚¿é¸æŠæ€§**: 12.4%

## âš¡ Photonã‚¨ãƒ³ã‚¸ãƒ³åˆ†æ
- **Photonæœ‰åŠ¹**: ã¯ã„
- **Photonåˆ©ç”¨ç‡**: 92.1%
- **æ¨å¥¨**: æœ€é©åŒ–æ¸ˆã¿

## ğŸ—‚ï¸ Liquid Clusteringæ¨å¥¨äº‹é …
**å¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«**: 3å€‹

**æ¨å¥¨å®Ÿè£…**:
- orders ãƒ†ãƒ¼ãƒ–ãƒ«: ALTER TABLE orders CLUSTER BY (customer_id, order_date)
- customers ãƒ†ãƒ¼ãƒ–ãƒ«: ALTER TABLE customers CLUSTER BY (region, customer_type)
```

### æœ€é©åŒ–ã•ã‚ŒãŸSQLã‚¯ã‚¨ãƒª
```sql
-- æœ€é©åŒ–å‰
SELECT customer_id, SUM(amount) 
FROM orders 
WHERE order_date >= '2023-01-01' 
GROUP BY customer_id;

-- æœ€é©åŒ–å¾Œ
SELECT /*+ BROADCAST(c) */ 
    o.customer_id, 
    SUM(o.amount) as total_amount
FROM orders o
JOIN customers c ON o.customer_id = c.customer_id
WHERE o.order_date >= '2023-01-01'
    AND c.status = 'active'
GROUP BY o.customer_id
ORDER BY total_amount DESC;
```

## ğŸ› ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

#### 1. LLMã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼
```
âŒ åˆ†æã‚¨ãƒ©ãƒ¼: Connection timeout
```
**è§£æ±ºæ–¹æ³•**:
- Databricks: Model Servingã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®çŠ¶æ…‹ç¢ºèª
- OpenAI/Azure/Anthropic: APIã‚­ãƒ¼ã¨ã‚¯ã‚©ãƒ¼ã‚¿ç¢ºèª
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã®ç¢ºèª

#### 2. ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼
```
âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: FileNotFoundError
```
**è§£æ±ºæ–¹æ³•**:
```python
# ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
dbutils.fs.ls("/FileStore/shared_uploads/")

# ãƒ‘ã‚¹å½¢å¼ã®ç¢ºèª
# æ­£ã—ã„: '/FileStore/shared_uploads/username/file.json'
# æ­£ã—ã„: '/Volumes/catalog/schema/volume/file.json'
```

#### 3. ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼
```
âŒ OutOfMemoryError: Java heap space
```
**è§£æ±ºæ–¹æ³•**:
- ã‚¯ãƒ©ã‚¹ã‚¿ã®ãƒ¡ãƒ¢ãƒªè¨­å®šã‚’å¢—åŠ 
- ã‚ˆã‚Šå¤§ããªã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚¿ã‚¤ãƒ—ã‚’ä½¿ç”¨
- è¤‡æ•°ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²å‡¦ç†

#### 4. å¤šè¨€èªæ–‡å­—åŒ–ã‘
```
âŒ UnicodeDecodeError
```
**è§£æ±ºæ–¹æ³•**:
```python
# UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ç¢ºèª
with open(file_path, 'r', encoding='utf-8') as file:
    data = json.load(file)
```

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®ãƒ’ãƒ³ãƒˆ

### 1. LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®é¸æŠ
- **é«˜é€Ÿå‡¦ç†**: Databricks Model Serving
- **é«˜å“è³ªåˆ†æ**: OpenAI GPT-4o
- **ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚º**: Azure OpenAI
- **ã‚³ã‚¹ãƒˆåŠ¹ç‡**: Anthropic Claude

### 2. å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
```python
# ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
import os
file_size = os.path.getsize(JSON_FILE_PATH)
print(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size / 1024 / 1024:.1f}MB")

# å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯åˆ†å‰²å‡¦ç†ã‚’æ¤œè¨
```

### 3. ä¸¦åˆ—å‡¦ç†
```python
# è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸¦åˆ—å‡¦ç†
from concurrent.futures import ThreadPoolExecutor

profiler_files = [file1, file2, file3]
with ThreadPoolExecutor(max_workers=3) as executor:
    results = list(executor.map(analyze_single_file, profiler_files))
```

## ğŸ”§ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### åˆ†æãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¿½åŠ 
```python
def extract_performance_metrics(profiler_data):
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¿½åŠ 
    metrics["custom_indicators"] = {
        "custom_metric_1": calculate_custom_metric_1(profiler_data),
        "custom_metric_2": calculate_custom_metric_2(profiler_data)
    }
    return metrics
```

### æ–°ã—ã„LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®è¿½åŠ 
```python
def _call_custom_llm(prompt: str) -> str:
    # ã‚«ã‚¹ã‚¿ãƒ LLMãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®å®Ÿè£…
    pass

# LLM_CONFIGã«è¿½åŠ 
LLM_CONFIG["custom_provider"] = {
    "api_key": "your-api-key",
    "endpoint": "your-endpoint"
}
```

## ğŸ“ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License

## ğŸ¤ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

1. ãƒ•ã‚©ãƒ¼ã‚¯ã™ã‚‹
2. æ©Ÿèƒ½ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆ (`git checkout -b feature/new-feature`)
3. ã‚³ãƒŸãƒƒãƒˆ (`git commit -am 'Add new feature'`)
4. ãƒ—ãƒƒã‚·ãƒ¥ (`git push origin feature/new-feature`)
5. ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ

## ğŸ“ ã‚µãƒãƒ¼ãƒˆ

- Issues: [GitHub Issues](https://github.com/your-username/databricks-sql-profiler-analysis/issues)
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: [Wiki](https://github.com/your-username/databricks-sql-profiler-analysis/wiki)
- ãƒ¡ãƒ¼ãƒ«: support@example.com

---

**æ³¨æ„**: ã“ã®ãƒ„ãƒ¼ãƒ«ã¯åˆ†æã¨æ¨å¥¨äº‹é …ã®æä¾›ã®ã¿ã‚’è¡Œã„ã¾ã™ã€‚æœ¬ç•ªç’°å¢ƒã§ã®å®Ÿè¡Œå‰ã«ã€å¿…ãšæ¨å¥¨äº‹é …ã‚’æ¤œè¨¼ã—ã¦ãã ã•ã„ã€‚
